{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "#import bcolz\n",
    "import csv\n",
    "import subprocess\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import preprocess_input\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Input, Dense, Flatten, Dropout, LeakyReLU, BatchNormalization, Conv2D, MaxPool2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "print (\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"data/xray_chest/images/\"\n",
    "img_height=224 #299\n",
    "img_width=224 #299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]\n",
    "\n",
    "def plot_img(img, title, count, cols, plot_axis=False):\n",
    "    a = fig.add_subplot(1, cols, count)\n",
    "    # if 'img' is a NumPy array, then it has already been loaded; just show it\n",
    "    if type(img).__module__ == np.__name__:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(load_img(img))\n",
    "    a.set_title(title,fontsize=10)\n",
    "    if plot_axis is False:\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_directories(csv_filename, img_path, is_one_v_all=False, one_v_all_label=\"Pneumonia\"):\n",
    "    directories = set()\n",
    "    with open(csv_filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(csvfile) # skip header row\n",
    "        for row in reader:\n",
    "            img_filename = str(row[0])\n",
    "            labels = str(row[1])\n",
    "            for label in labels.split('|'):\n",
    "                if (is_one_v_all is True) and (label != one_v_all_label):\n",
    "                    label = \"ALL\"\n",
    "                src_file = os.path.join(img_path,img_filename)\n",
    "                label = \"_\".join(label.split())\n",
    "                dst_train_dir = os.path.join(img_path,\"train\",label)\n",
    "                dst_train_file = os.path.join(dst_train_dir,img_filename)\n",
    "                dst_valid_dir = os.path.join(img_path,\"valid\",label)\n",
    "                dst_test_dir = os.path.join(img_path,\"test\",label)\n",
    "                if not os.path.exists(dst_train_dir):\n",
    "                    os.makedirs(dst_train_dir)\n",
    "                    directories.add(label)\n",
    "                if not os.path.exists(dst_valid_dir):\n",
    "                    os.makedirs(dst_valid_dir)\n",
    "                if not os.path.exists(dst_test_dir):\n",
    "                    os.makedirs(dst_test_dir)\n",
    "                src_file_abs = os.path.join(os.getcwd(),src_file)\n",
    "                dst_train_file_abs = os.path.join(os.getcwd(),dst_train_file)\n",
    "                #print(\"copy: \" + src_file_abs + \" to: \" + dst_train_file_abs)\n",
    "                if not os.path.exists(dst_train_file_abs):\n",
    "                    os.symlink(src_file_abs, dst_train_file_abs)\n",
    "    return list(directories)\n",
    "\n",
    "is_one_v_all = True\n",
    "one_v_all_label = \"Pneumonia\"\n",
    "print(img_path)\n",
    "directories = create_label_directories(\"data/xray_chest/Data_Entry_2017.csv\", img_path, is_one_v_all, one_v_all_label)\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_label_count(directories):\n",
    "    per_label_count = []\n",
    "    for ii in range(len(directories)):\n",
    "        #print(directories[ii])\n",
    "        path, dirs, files = os.walk(os.path.join(img_path,\"train\",directories[ii])).__next__()\n",
    "        file_count = len(files)\n",
    "        per_label_count.append(file_count)\n",
    "    return per_label_count\n",
    "        \n",
    "print(directories)\n",
    "per_label_count = get_per_label_count(directories) \n",
    "print(per_label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(directories, per_label_count, iqr):\n",
    "    for ii in range(len(per_label_count)):\n",
    "        label = directories[ii]\n",
    "        count = per_label_count[ii]\n",
    "        if count < iqr:\n",
    "            offset = iqr-count\n",
    "#            subprocess.call(['./batch-augment.sh', os.path.join(os.getcwd(),img_path,\"train\",label), str(offset)])\n",
    "    return get_per_label_count(directories)\n",
    "\n",
    "print(directories)\n",
    "print(per_label_count)\n",
    "#print(label_batch_size)\n",
    "per_label_count_upsampled = upsample(directories, per_label_count, 8430)#label_batch_size)\n",
    "print(per_label_count_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(directories, per_label_count):\n",
    "    label_idx = np.argmin(per_label_count)\n",
    "    #print(label_idx)\n",
    "    downsample_count = per_label_count[label_idx]\n",
    "    #print(downsample_count)\n",
    "    for ii in range(len(per_label_count)):\n",
    "        label = directories[ii]\n",
    "        src_train_dir = os.path.join(img_path,\"train\",label)\n",
    "        all_img_paths = glob.glob(os.path.join(src_train_dir,\"*.*\"))\n",
    "        np.random.shuffle(all_img_paths)\n",
    "        if len(all_img_paths) != downsample_count:\n",
    "            imgs_to_remove = all_img_paths[downsample_count:]\n",
    "            #print(len(imgs_to_remove))\n",
    "            for file in imgs_to_remove:\n",
    "                file_abs = os.path.join(os.getcwd(),file)\n",
    "                #print(\"remove file: \" + file_abs)\n",
    "                os.remove(file_abs)\n",
    "    return get_per_label_count(directories)\n",
    "                \n",
    "print(directories)\n",
    "print(per_label_count_upsampled)\n",
    "per_label_count_downsampled = downsample(directories, per_label_count_upsampled)\n",
    "print(per_label_count_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_test(directories, per_label_count, valid_pct, test_pct):\n",
    "    for ii in range(len(directories)):\n",
    "        all_img_paths = glob.glob(os.path.join(img_path,\"train\",directories[ii],\"*.*\"))\n",
    "        np.random.shuffle(all_img_paths)\n",
    "        label_count = per_label_count[ii]\n",
    "        valid_count = int(label_count*valid_pct)\n",
    "        valid_files = all_img_paths[:valid_count]\n",
    "        all_img_paths[:valid_count] = []\n",
    "        test_count = int(label_count*test_pct)\n",
    "        test_files = all_img_paths[:test_count]\n",
    "        all_img_paths[:test_count] = []\n",
    "        #print(len(valid_files))\n",
    "        #print(len(test_files))\n",
    "        train_files = all_img_paths\n",
    "        all_img_paths = []\n",
    "        #print(len(train_files))\n",
    "        for valid_file in valid_files:\n",
    "            valid_file_abs = os.path.join(os.getcwd(),valid_file)\n",
    "            #print(\"move: '\" + valid_file_abs + \"' to: '\" + os.path.join(img_path,\"valid\",directories[ii]))\n",
    "            shutil.move(valid_file_abs, os.path.join(img_path,\"valid\",directories[ii]))\n",
    "        for test_file in test_files:\n",
    "            test_file_abs = os.path.join(os.getcwd(),test_file)\n",
    "            #print(\"move: '\" + test_file_abs + \"' to: '\" + os.path.join(img_path,\"test\",directories[ii]))\n",
    "            shutil.move(test_file_abs, os.path.join(img_path,\"test\",directories[ii]))\n",
    "        \n",
    "\n",
    "valid_pct = 0.01 # 0.1\n",
    "test_pct = 0.98 # 0.1       \n",
    "print(directories)\n",
    "print(per_label_count_downsampled)\n",
    "split_train_valid_test(directories, per_label_count_downsampled, valid_pct, test_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    #horizontal_flip=True, \n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/xray_chest/images/train',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "    #color_mode='grayscale')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'data/xray_chest/images/valid',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size, #val_batch_size,\n",
    "    class_mode='categorical')\n",
    "    \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/xray_chest/images/test',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(include_top=True, weights=None, input_shape=(img_width,img_height,3), classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('weights.best.DenseNet121-nih-one-v-all-fibrosis.20180305-r1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.best.DenseNet121-nih-one-v-all-fibrosis.20180305-r1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min') #mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=500)\n",
    "callbacks_list = [checkpoint,early_stopping]#,tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial dataset modified to work with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final image resolution\n",
    "res = 64\n",
    "\n",
    "# Crop images to squares\n",
    "def to_square(img):\n",
    "    (h, w) = img.shape\n",
    "    diff_half = np.abs(h-w) // 2\n",
    "    \n",
    "    if w > h:\n",
    "        return(img[0:h, 0+diff_half:w-diff_half])\n",
    "    elif w < h:\n",
    "        return(img[0+diff_half:w-diff_half, 0:w])\n",
    "    else: \n",
    "        return img\n",
    "\n",
    "def load_data(dataset='train'):\n",
    "    \n",
    "    # Path where files are stored\n",
    "    files_path = 'data/xray_chest/images/'+dataset\n",
    "    \n",
    "    #--- STEP 1: Create list containing names of image files ---#\n",
    "    names_list = []\n",
    "    for cat in ['/ALL', '/Pneumonia']:\n",
    "        for img_name in os.listdir(files_path+cat):\n",
    "            # Exclude non-image files\n",
    "            if img_name[0] in ['I', 'N', 'p']:\n",
    "                names_list.append(img_name)\n",
    "    # Shuffle to feed into network\n",
    "    random.Random(232).shuffle(names_list)\n",
    "    \n",
    "    #--- STEP 2: Create list of labels ---#\n",
    "    labels = []\n",
    "    for img_name in names_list:\n",
    "        # 0 for normal, 1 for pneumonia\n",
    "        if img_name[0] in ['I', 'N']:\n",
    "            labels.append(0)\n",
    "        elif img_name[0] == 'p':\n",
    "            labels.append(1)\n",
    "            \n",
    "    #--- STEP 3: Load images and process them ---#\n",
    "    img_list = []\n",
    "    for img_name in tqdm(names_list):\n",
    "        try:\n",
    "            # Load images \n",
    "            if img_name[0] in ['I', 'N']:\n",
    "                img = plt.imread(files_path+'/ALL/'+img_name)\n",
    "            elif img_name[0] == 'p':\n",
    "                img = plt.imread(files_path+'/Pneumonia/'+img_name)\n",
    "                \n",
    "            # Process images (normalize, square, reduce resolution)\n",
    "            if len(img.shape) == 3:\n",
    "                img = img[:,:,0]\n",
    "            img = img / 255\n",
    "            img = to_square(img)\n",
    "            img = cv2.resize(img, dsize=(res, res), interpolation=cv2.INTER_AREA)\n",
    "            img = img.reshape(res, res, 1)\n",
    "            img = np.dstack([img, img, img])\n",
    "            img_list.append(img)\n",
    "        except OSError:\n",
    "            pass\n",
    "    \n",
    "    return np.array(img_list), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \r"
     ]
    }
   ],
   "source": [
    "# Load data into each dataset pair\n",
    "x_train, y_train = load_data(dataset='train')\n",
    "x_val, y_val = load_data(dataset='valid')\n",
    "x_test, y_test = load_data(dataset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-614047ec5bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing xrays\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30, 10))\n",
    "ax = ax.ravel()\n",
    "plt.tight_layout(h_pad=3)\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "    ax[i].imshow(x_test[i], cmap='gray')\n",
    "    ax[i].set_title('label = {}'.format(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "ks33 = (3, 3)\n",
    "ks22 = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design model with Keras Functional API \n",
    "inputs = Input(shape=(res, res, 3))\n",
    "\n",
    "# Convolutional layer 1\n",
    "conv1 = Conv2D(filters=16, kernel_size=ks33, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(filters=16, kernel_size=ks33, activation='relu', padding='same')(conv1)\n",
    "conv1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "# Convolutional layer 2\n",
    "conv2 = Conv2D(filters=32, kernel_size=ks33, activation='relu', padding='same')(conv1)\n",
    "conv2 = Conv2D(filters=32, kernel_size=ks33, activation='relu', padding='same')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Convolutional layer 3\n",
    "conv3 = Conv2D(filters=64, kernel_size=ks33, activation='relu', padding='same')(conv2)\n",
    "conv3 = Conv2D(filters=64, kernel_size=ks33, activation='relu', padding='same')(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "# Fully-Connected layer\n",
    "fc = Flatten()(conv3)\n",
    "fc = Dense(units=256, activation='relu')(fc)\n",
    "fc = Dropout(rate=0.5)(fc)\n",
    "fc = Dense(units=64, activation='relu')(fc)\n",
    "fc = Dropout(rate=0.2)(fc)\n",
    "\n",
    "# Output\n",
    "output = Dense(units=1, activation='sigmoid')(fc)\n",
    "\n",
    "# Create model and compile\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks and image preprocessing\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "img_aug = ImageDataGenerator(rotation_range=20, vertical_flip=True, horizontal_flip=True)\n",
    "img_aug.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for fitting\n",
    "batch_size = 74\n",
    "epochs = 40\n",
    "steps = x_train.shape[0] // batch_size\n",
    "\n",
    "# Fitting model to data (val set too small, use test for validation)\n",
    "model.fit_generator(img_aug.flow(x_train, y_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=steps, epochs=epochs, \n",
    "                    validation_data=(x_test, y_test), callbacks=[reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "# Getting predictions\n",
    "predictions = model.predict(x=x_test)\n",
    "\n",
    "acc = accuracy_score(y_test, np.round(predictions))*100\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, np.round(predictions)).ravel()\n",
    "\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(tp/(tp+fp)*100))\n",
    "print('Recall: {}%'.format(tp/(tp+fn)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, np.round(predictions)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to orginal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_train_samples = 16188 #8094 #3036 #18046 #111589 #113243 #139987 \n",
    "nb_train_samples = 88\n",
    "nb_validation_samples= 336 \n",
    "epochs = int(nb_train_samples/batch_size)*3\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=batch_size, #nb_train_samples/batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=batch_size, #nb_validation_samples/batch_size, #val_batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'],'r--')\n",
    "    plt.plot(history.history['val_loss'],'b-')\n",
    "    plt.title('Model Loss')\n",
    "    plt.legend(['Train Loss', 'Valid Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show();\n",
    "    plt.plot(history.history['acc'],'r--')\n",
    "    plt.plot(history.history['val_acc'],'b-')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.legend(['Train Acc', 'Valid Acc'])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "\n",
    "# requires history=model.fit, fit_generator...\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=10, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "print(\"score = Loss: %f, Acc@1: %.2f\" % (scores[0],scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator, steps=10, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_generator.classes)\n",
    "steps = 11 #int(SIZE?/batch_size)\n",
    "preds = np.zeros((0,2))\n",
    "y_test = np.zeros((0,2))\n",
    "step_count = 0\n",
    "for batch_x, batch_y in test_generator:\n",
    "    if step_count < steps:\n",
    "        batch_preds = model.predict(batch_x)\n",
    "        #print(batch_preds.shape)\n",
    "        preds = np.vstack((preds,batch_preds))\n",
    "        #print(batch_y)\n",
    "        y_test = np.vstack((y_test,batch_y))\n",
    "        step_count = step_count + 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print(preds.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = [np.argmax(ii) for ii in y_test]\n",
    "y_preds = [np.argmax(ii) for ii in preds]\n",
    "\n",
    "# credit: https://tatwan.github.io/How-To-Plot-A-Confusion-Matrix-In-Python/    \n",
    "def plot_binary_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    classNames = classes\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    \n",
    "cm = confusion_matrix(y_trues, y_preds)\n",
    "#print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "#print(tn, fp, fn, tp)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_binary_confusion_matrix(cm, classes=['Negative','Positive'], title='Confusion matrix, without normalization', cmap=plt.cm.Greens)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
